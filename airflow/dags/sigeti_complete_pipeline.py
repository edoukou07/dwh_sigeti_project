#!/usr/bin/env python3
"""
DAG Airflow pour le pipeline ETL des Collectes, Recouvrements et Indicateurs Financiers SIGETI
Orchestration de l'extraction, transformation et cr√©ation des KPI complets
"""

from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.operators.bash_operator import BashOperator
from airflow.operators.dummy_operator import DummyOperator
from airflow.utils.dates import days_ago
from datetime import datetime, timedelta
import sys
import os

# Ajouter le chemin des scripts
sys.path.append('/opt/airflow/scripts')

# Configuration du DAG
default_args = {
    'owner': 'sigeti-admin',
    'depends_on_past': False,
    'start_date': days_ago(1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    'catchup': False
}

# Cr√©ation du DAG
dag = DAG(
    'sigeti_collectes_recouvrement_financial_pipeline',
    default_args=default_args,
    description='Pipeline ETL complet pour Collectes, Recouvrements et Indicateurs Financiers SIGETI',
    schedule_interval='0 6 * * *',  # Tous les jours √† 6h00
    max_active_runs=1,
    tags=['sigeti', 'collectes', 'recouvrement', 'kpi', 'finance', 'paiements']
)

def run_etl_collectes():
    """Ex√©cuter l'ETL des collectes et recouvrements"""
    try:
        from etl_collectes_pandas import ETLCollectesRecouvrements
        
        etl = ETLCollectesRecouvrements()
        success = etl.run_etl()
        
        if not success:
            raise Exception("ETL des collectes et recouvrements √©chou√©")
        
        print("‚úÖ ETL collectes termin√© avec succ√®s")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur ETL collectes: {e}")
        raise

def run_etl_financial_to_dimensional():
    """Ex√©cuter l'ETL financier vers le mod√®le dimensionnel"""
    try:
        import sys
        sys.path.append('/opt/airflow/scripts')
        
        # Importer et ex√©cuter l'ETL financier
        exec(open('/opt/airflow/scripts/etl_financial_to_dimensional.py').read())
        
        print("‚úÖ ETL financier vers dimensionnel termin√© avec succ√®s")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur ETL financier dimensionnel: {e}")
        raise

def create_kpi_views():
    """Cr√©er les vues KPI des collectes"""
    try:
        from create_kpi_collectes_views import deploy_kpi_views, test_kpi_views
        
        # D√©ployer les vues KPI
        if not deploy_kpi_views():
            raise Exception("√âchec du d√©ploiement des vues KPI collectes")
        
        # Tester les vues
        if not test_kpi_views():
            raise Exception("√âchec des tests des vues KPI collectes")
        
        print("‚úÖ Vues KPI collectes cr√©√©es et test√©es avec succ√®s")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur cr√©ation KPI collectes: {e}")
        raise

def create_financial_kpi_views():
    """Cr√©er les vues KPI financiers"""
    try:
        import psycopg2
        import os
        
        # Configuration de la base
        db_config = {
            'host': os.getenv('DWH_DB_HOST', 'localhost'),
            'port': os.getenv('DWH_DB_PORT', 5432),
            'database': os.getenv('DWH_DB_NAME', 'sigeti_dwh'),
            'user': os.getenv('DWH_DB_USER', 'sigeti_user'),
            'password': os.getenv('DWH_DB_PASSWORD', 'sigeti123')
        }
        
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        
        # Liste des vues KPI √† cr√©er
        kpi_financial_views = [
            '''CREATE OR REPLACE VIEW v_kpi_montant_total_paiements AS
            SELECT 'Montant Total des Paiements Re√ßus' as indicateur,
                   SUM(montant_paiement) as valeur,
                   'FCFA' as unite,
                   COUNT(*) as nombre_transactions,
                   CURRENT_DATE as date_calcul
            FROM fct_paiements WHERE montant_paiement > 0''',
            
            '''CREATE OR REPLACE VIEW v_kpi_revenus_paiements_reussis AS
            SELECT 'Revenus Totaux des Paiements R√©ussis' as indicateur,
                   SUM(montant_net) as valeur,
                   'FCFA' as unite,
                   COUNT(*) as nombre_paiements_reussis,
                   ROUND(AVG(montant_net), 2) as montant_moyen,
                   CURRENT_DATE as date_calcul
            FROM fct_paiements 
            WHERE statut_paiement_key IN ('PAYE_COMPLET', 'PAYE_PARTIEL', 'RECOUVRE')''',
            
            '''CREATE OR REPLACE VIEW v_dashboard_financier_complet AS
            SELECT 1 as ordre, '1. Montant Total Paiements' as kpi,
                   CONCAT(ROUND(valeur/1000000, 1), 'M FCFA') as valeur,
                   CONCAT(nombre_transactions, ' transactions') as detail
            FROM v_kpi_montant_total_paiements
            UNION ALL
            SELECT 2 as ordre, '2. Revenus Nets R√©ussis' as kpi,
                   CONCAT(ROUND(valeur/1000000, 1), 'M FCFA') as valeur,
                   CONCAT(nombre_paiements_reussis, ' paiements') as detail
            FROM v_kpi_revenus_paiements_reussis
            ORDER BY ordre'''
        ]
        
        # Ex√©cuter chaque vue
        for view_sql in kpi_financial_views:
            cursor.execute(view_sql)
        
        conn.commit()
        cursor.close()
        conn.close()
        
        print("‚úÖ Vues KPI financiers cr√©√©es avec succ√®s")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur cr√©ation KPI financiers: {e}")
        raise

def validate_collectes_data():
    """Valider les donn√©es de collectes charg√©es"""
    try:
        import psycopg2
        import os
        
        # Configuration de la base
        db_config = {
            'host': os.getenv('DWH_DB_HOST', 'localhost'),
            'port': os.getenv('DWH_DB_PORT', 5432),
            'database': os.getenv('DWH_DB_NAME', 'sigeti_dwh'),
            'user': os.getenv('DWH_DB_USER', 'sigeti_user'),
            'password': os.getenv('DWH_DB_PASSWORD', 'sigeti123')
        }
        
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        
        validations = []
        
        # Validation 1: V√©rifier les donn√©es de collectes
        cursor.execute("SELECT COUNT(*) FROM fct_collectes")
        count_collectes = cursor.fetchone()[0]
        validations.append(f"‚úÖ Collectes: {count_collectes} enregistrements")
        
        # Validation 2: V√©rifier les donn√©es de paiements
        cursor.execute("SELECT COUNT(*) FROM fct_paiements")
        count_paiements = cursor.fetchone()[0]
        validations.append(f"‚úÖ Paiements: {count_paiements} enregistrements")
        
        # Validation 3: V√©rifier les vues KPI
        cursor.execute("SELECT COUNT(*) FROM v_dashboard_financier_complet")
        count_kpi = cursor.fetchone()[0]
        validations.append(f"‚úÖ KPI Financiers: {count_kpi} indicateurs")
        
        cursor.close()
        conn.close()
        
        for validation in validations:
            print(validation)
        
        print("‚úÖ Validation des donn√©es r√©ussie")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur validation donn√©es: {e}")
        raise

def generate_complete_report():
    """G√©n√©rer le rapport complet collectes et financier"""
    try:
        import psycopg2
        import os
        from datetime import datetime
        
        # Configuration de la base
        db_config = {
            'host': os.getenv('DWH_DB_HOST', 'localhost'),
            'port': os.getenv('DWH_DB_PORT', 5432),
            'database': os.getenv('DWH_DB_NAME', 'sigeti_dwh'),
            'user': os.getenv('DWH_DB_USER', 'sigeti_user'),
            'password': os.getenv('DWH_DB_PASSWORD', 'sigeti123')
        }
        
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        
        # G√©n√©rer le rapport financier
        cursor.execute("SELECT kpi, valeur, detail FROM v_dashboard_financier_complet ORDER BY ordre")
        rapport_financier = cursor.fetchall()
        
        # Cr√©er le rapport complet
        rapport_contenu = f"""# RAPPORT COLLECTES, RECOUVREMENTS ET INDICATEURS FINANCIERS SIGETI
## G√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## üí∞ INDICATEURS FINANCIERS ET DE PAIEMENT

"""
        
        # Ajouter les KPI financiers
        if rapport_financier:
            for kpi in rapport_financier:
                rapport_contenu += f"""### {kpi[0]}
- **Valeur**: {kpi[1]}
- **D√©tail**: {kpi[2]}

"""
        
        rapport_contenu += """
## üìä R√âSUM√â TECHNIQUE
- Architecture: PostgreSQL Dimensionnelle
- Pipeline ETL: Airflow
- KPI: Temps r√©el via vues mat√©rialis√©es
- Fr√©quence: Quotidienne √† 6h00

---
*Rapport g√©n√©r√© automatiquement par le pipeline SIGETI ETL*
"""
        
        # Sauvegarder le rapport
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        rapport_path = f'/opt/airflow/reports/rapport_sigeti_complet_{timestamp}.md'
        
        os.makedirs('/opt/airflow/reports', exist_ok=True)
        with open(rapport_path, 'w', encoding='utf-8') as f:
            f.write(rapport_contenu)
        
        print(f"‚úÖ Rapport sauvegard√©: {rapport_path}")
        print(rapport_contenu)
        
        cursor.close()
        conn.close()
        
        print("‚úÖ G√©n√©ration rapport termin√©e avec succ√®s")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©ration rapport: {e}")
        raise

# D√©finition des t√¢ches

# T√¢che de d√©but
start_task = DummyOperator(
    task_id='start_sigeti_complete_pipeline',
    dag=dag
)

# ETL des collectes et recouvrements
etl_collectes_task = PythonOperator(
    task_id='etl_collectes_recouvrements',
    python_callable=run_etl_collectes,
    dag=dag
)

# ETL financier vers dimensionnel
etl_financial_task = PythonOperator(
    task_id='etl_financial_to_dimensional',
    python_callable=run_etl_financial_to_dimensional,
    dag=dag
)

# Ex√©cution des mod√®les dbt (mod√®les staging)
dbt_staging_task = BashOperator(
    task_id='dbt_run_staging_collectes',
    bash_command="""
    cd /opt/airflow/dbt_sigeti && 
    dbt run --models staging.stg_collectes staging.stg_agents_collecteurs staging.stg_recouvrements
    """,
    dag=dag
)

# Ex√©cution des mod√®les dbt (dimensions et faits)
dbt_marts_task = BashOperator(
    task_id='dbt_run_marts_collectes',
    bash_command="""
    cd /opt/airflow/dbt_sigeti && 
    dbt run --models marts.dim_agents_collecteurs marts.fct_collectes_recouvrements
    """,
    dag=dag
)

# Cr√©ation des vues KPI collectes
kpi_views_task = PythonOperator(
    task_id='create_collectes_kpi_views',
    python_callable=create_kpi_views,
    dag=dag
)

# Cr√©ation des vues KPI financiers
financial_kpi_views_task = PythonOperator(
    task_id='create_financial_kpi_views',
    python_callable=create_financial_kpi_views,
    dag=dag
)

# Tests dbt
dbt_test_task = BashOperator(
    task_id='dbt_test_collectes',
    bash_command="""
    cd /opt/airflow/dbt_sigeti && 
    dbt test --models staging.stg_collectes staging.stg_agents_collecteurs marts.dim_agents_collecteurs marts.fct_collectes_recouvrements
    """,
    dag=dag,
    trigger_rule='none_failed'
)

# Validation des donn√©es
validation_task = PythonOperator(
    task_id='validate_complete_data',
    python_callable=validate_collectes_data,
    dag=dag
)

# G√©n√©ration du rapport complet
report_task = PythonOperator(
    task_id='generate_complete_report',
    python_callable=generate_complete_report,
    dag=dag
)

# T√¢che de fin
end_task = DummyOperator(
    task_id='end_sigeti_complete_pipeline',
    dag=dag
)

# D√©finition des d√©pendances du pipeline complet
start_task >> etl_collectes_task
etl_collectes_task >> [dbt_staging_task, etl_financial_task]
dbt_staging_task >> dbt_marts_task
dbt_marts_task >> kpi_views_task
etl_financial_task >> financial_kpi_views_task

# Correction: connecter les t√¢ches individuellement
kpi_views_task >> [dbt_test_task, validation_task]
financial_kpi_views_task >> [dbt_test_task, validation_task]

[dbt_test_task, validation_task] >> report_task
report_task >> end_task