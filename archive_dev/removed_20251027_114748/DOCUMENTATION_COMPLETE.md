# SIGETI Data Warehouse - Documentation ComplÃ¨te

## ğŸ—ï¸ Architecture Globale

Le projet SIGETI Data Warehouse est une solution complÃ¨te d'entrepÃ´t de donnÃ©es pour la gestion et l'analyse des demandes d'attribution de terrains industriels en Tunisie.

### ğŸ¯ Objectifs
- Centraliser les donnÃ©es des demandes d'attribution
- Automatiser les processus ETL
- Fournir des indicateurs de performance (KPI)
- Permettre l'analyse dÃ©cisionnelle

### ğŸ“Š Indicateurs ClÃ©s (KPI)
1. **Taux d'acceptation** des demandes
2. **DÃ©lai de traitement** moyen
3. **Volume des demandes** par pÃ©riode
4. **Performance financiÃ¨re** et emploi
5. **Analyse temporelle** des tendances
6. **RÃ©partition gÃ©ographique** par zone
7. **Tableau de bord exÃ©cutif** consolidÃ©

## ğŸ›ï¸ Architecture Technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   sigeti_node_dbâ”‚    â”‚   SIGETI ETL     â”‚    â”‚   sigeti_dwh    â”‚
â”‚   (Source)      â”‚â”€â”€â”€â–¶â”‚   Pipeline       â”‚â”€â”€â”€â–¶â”‚   (Target)      â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ demandes      â”‚    â”‚ â€¢ Python Script  â”‚    â”‚ â€¢ staging       â”‚
â”‚ â€¢ entreprises   â”‚    â”‚ â€¢ Data Cleaning  â”‚    â”‚ â€¢ marts         â”‚
â”‚ â€¢ lots_terrain  â”‚    â”‚ â€¢ UTF-8 Encoding â”‚    â”‚ â€¢ KPI Views     â”‚
â”‚ â€¢ zones_indus   â”‚    â”‚                  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
         â”‚              â”‚   dbt Project    â”‚              â”‚
         â”‚              â”‚                  â”‚              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â€¢ Transformationsâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ â€¢ Star Schema    â”‚
                        â”‚ â€¢ Data Quality   â”‚
                        â”‚ â€¢ Documentation  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Apache Airflow     â”‚
                     â”‚                      â”‚
                     â”‚ â€¢ Pipeline Scheduler â”‚
                     â”‚ â€¢ KPI Monitoring     â”‚
                     â”‚ â€¢ Error Handling     â”‚
                     â”‚ â€¢ Notifications      â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Structure du Projet

```
SIGETI_DWH/
â”œâ”€â”€ ğŸ“ airflow/                    # Orchestration Apache Airflow
â”‚   â”œâ”€â”€ ğŸ“ dags/                  # DÃ©finitions des DAGs
â”‚   â”‚   â”œâ”€â”€ sigeti_etl_pipeline.py          # Pipeline ETL principal
â”‚   â”‚   â””â”€â”€ sigeti_kpi_monitoring.py        # Monitoring KPI
â”‚   â”œâ”€â”€ ğŸ“ logs/                  # Logs d'exÃ©cution
â”‚   â”œâ”€â”€ ğŸ“ plugins/               # Plugins personnalisÃ©s
â”‚   â”œâ”€â”€ airflow.cfg               # Configuration Airflow
â”‚   â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”‚   â”œâ”€â”€ setup_airflow.py         # Script d'installation
â”‚   â”œâ”€â”€ start_scheduler.bat      # DÃ©marrage scheduler (Windows)
â”‚   â”œâ”€â”€ start_webserver.bat      # DÃ©marrage serveur web (Windows)
â”‚   â””â”€â”€ README.md                 # Documentation Airflow
â”‚
â”œâ”€â”€ ğŸ“ dbt_sigeti/                # Projet dbt
â”‚   â”œâ”€â”€ ğŸ“ models/               # ModÃ¨les de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ ğŸ“ staging/          # Tables de staging
â”‚   â”‚   â””â”€â”€ ğŸ“ marts/           # Tables finales (star schema)
â”‚   â”‚       â””â”€â”€ ğŸ“ core/        # Fait et dimensions
â”‚   â”œâ”€â”€ ğŸ“ tests/               # Tests de qualitÃ©
â”‚   â”œâ”€â”€ ğŸ“ macros/              # Macros dbt
â”‚   â”œâ”€â”€ dbt_project.yml         # Configuration projet
â”‚   â”œâ”€â”€ profiles.yml            # Configuration connexions
â”‚   â””â”€â”€ packages.yml            # Packages dbt
â”‚
â”œâ”€â”€ ğŸ“ sql_views/                 # Vues KPI SQL
â”‚   â”œâ”€â”€ 01_v_kpi_taux_acceptation.sql      # Taux d'acceptation
â”‚   â”œâ”€â”€ 02_v_kpi_delai_traitement.sql      # DÃ©lais de traitement
â”‚   â”œâ”€â”€ 03_v_kpi_volume_demandes.sql       # Volume des demandes
â”‚   â”œâ”€â”€ 04_v_kpi_performance_financiere.sql # Performance financiÃ¨re
â”‚   â”œâ”€â”€ 05_v_kpi_analyse_temporelle.sql    # Analyse temporelle
â”‚   â”œâ”€â”€ 06_v_kpi_repartition_geographique.sql # RÃ©partition gÃ©o
â”‚   â”œâ”€â”€ 07_v_kpi_tableau_bord_executif.sql # Tableau de bord
â”‚   â”œâ”€â”€ deploy_views.sql                   # Script de dÃ©ploiement
â”‚   â””â”€â”€ README.md                          # Documentation vues
â”‚
â”œâ”€â”€ ğŸ“„ etl_sigeti.py              # Script ETL principal (Python/Pandas)
â”œâ”€â”€ ğŸ“„ etl_sigeti_spark.py        # Script ETL PySpark (alternatif)
â”œâ”€â”€ ğŸ“„ create_kpi_views.py        # CrÃ©ation automatique des vues
â”œâ”€â”€ ğŸ“„ test_kpi_views.py          # Tests et validation des vues
â”œâ”€â”€ ğŸ“„ validate_pipeline.py       # Validation complÃ¨te du pipeline
â”œâ”€â”€ ğŸ“„ kpi_manager.bat            # Gestionnaire vues KPI (Windows)
â””â”€â”€ ğŸ“„ README.md                  # Documentation principale
```

## ğŸš€ DÃ©ploiement et Installation

### PrÃ©requis
- Python 3.8+
- PostgreSQL 12+
- dbt-core 1.7+
- Apache Airflow 2.8+

### Installation pas Ã  pas

#### 1. Base de donnÃ©es
```sql
-- CrÃ©er les bases de donnÃ©es
CREATE DATABASE sigeti_node_db;  -- Base source
CREATE DATABASE sigeti_dwh;      -- EntrepÃ´t de donnÃ©es
```

#### 2. Environnement Python
```bash
cd c:\Users\hynco\Desktop\SIGETI_DWH
pip install -r requirements.txt
```

#### 3. Configuration dbt
```bash
cd dbt_sigeti
dbt deps --profiles-dir .
dbt debug --profiles-dir .
```

#### 4. Installation Airflow
```bash
cd airflow
python setup_airflow.py
```

#### 5. DÃ©ploiement initial
```bash
# ETL initial
python etl_sigeti.py

# Transformations dbt
cd dbt_sigeti
dbt run --profiles-dir .

# CrÃ©ation des vues KPI
cd ..
python create_kpi_views.py
```

## ğŸ”„ Utilisation Quotidienne

### Pipeline Automatique (Airflow)
```bash
# DÃ©marrer Airflow
cd airflow
start_scheduler.bat    # Terminal 1
start_webserver.bat    # Terminal 2

# Interface web: http://localhost:8080
# Login: admin / admin123
```

### ExÃ©cution Manuelle
```bash
# Pipeline complet
python validate_pipeline.py

# ETL seul
python etl_sigeti.py

# Vues KPI seules
python create_kpi_views.py

# Tests
python test_kpi_views.py --summary
```

### Gestion des KPI
```bash
# Interface interactive
kpi_manager.bat

# Commandes directes
kpi_manager.bat deploy   # DÃ©ployer les vues
kpi_manager.bat test     # Tester les vues
kpi_manager.bat summary  # RÃ©sumÃ© exÃ©cutif
```

## ğŸ“Š ModÃ¨le de DonnÃ©es

### Star Schema
- **Fait**: `fct_demandes_attribution` (table centrale)
- **Dimensions**:
  - `dim_entreprises` (entreprises)
  - `dim_zones_industrielles` (zones)
  - `dim_lots` (lots de terrain)
  - `dim_statuts_demandes` (statuts)
  - `dim_date` (dates)

### MÃ©triques Principales
- Nombre de demandes
- Taux d'acceptation
- DÃ©lais de traitement
- Montants financÃ©s
- Emplois crÃ©Ã©s

## ğŸ” Monitoring et Alertes

### Seuils d'Alerte
- **Taux d'acceptation**: < 30% = Alerte
- **DÃ©lai moyen**: > 15 jours = Alerte
- **Volume**: Variations importantes = Avertissement

### Notifications
- Email automatique en cas d'erreur
- Rapports quotidiens gÃ©nÃ©rÃ©s
- Tableau de bord temps rÃ©el

## ğŸ› ï¸ Maintenance

### TÃ¢ches RÃ©guliÃ¨res
- **Quotidien**: VÃ©rification des logs, validation des KPI
- **Hebdomadaire**: Analyse des tendances, optimisation
- **Mensuel**: RÃ©vision des seuils, mise Ã  jour documentation

### Troubleshooting
```bash
# Diagnostics
python validate_pipeline.py     # Validation complÃ¨te
dbt test --profiles-dir .       # Tests de qualitÃ©
python test_kpi_views.py --test # Tests des vues

# Logs
tail -f airflow/logs/scheduler/latest/*.log
tail -f airflow/logs/dag_id/task_id/*/1.log
```

## ğŸ“ˆ Performances

### MÃ©triques Actuelles
- **Volume de donnÃ©es**: ~77 enregistrements
- **Temps d'exÃ©cution ETL**: ~30 secondes
- **Temps dbt**: ~15 secondes
- **Temps total pipeline**: ~2 minutes

### Optimisations
- Index sur les clÃ©s Ã©trangÃ¨res
- Partitionnement par date si volume important
- Mise en cache des vues frÃ©quemment utilisÃ©es

## ğŸ” SÃ©curitÃ©

### AccÃ¨s aux DonnÃ©es
- Authentification PostgreSQL requise
- Connexions chiffrÃ©es
- Audit des accÃ¨s via logs

### Sauvegarde
- Backup automatique PostgreSQL
- Versioning du code (Git recommandÃ©)
- Documentation des changements

## ğŸ¯ Roadmap Future

### AmÃ©liorations PrÃ©vues
1. **Dashboards interactifs** (Power BI/Grafana)
2. **API REST** pour l'accÃ¨s aux donnÃ©es
3. **Alertes intelligentes** avec ML
4. **Historisation** des changements
5. **IntÃ©gration** avec d'autres systÃ¨mes

### Ã‰volutions Techniques
- Migration vers Apache Spark pour gros volumes
- ImplÃ©mentation de Delta Lake
- CI/CD pour dbt et Airflow
- Containerisation avec Docker

## ğŸ“ Support

### Documentation
- README principal: `/README.md`
- Documentation Airflow: `/airflow/README.md`
- Documentation vues KPI: `/sql_views/README.md`

### Validation
```bash
python validate_pipeline.py  # Test complet
```

### Contacts
- **Ã‰quipe technique**: [Votre Ã©quipe]
- **Business owner**: [Responsable mÃ©tier]
- **Support IT**: [Support informatique]

---

**Version**: 1.0  
**DerniÃ¨re mise Ã  jour**: 27 octobre 2025  
**Status**: Production Ready âœ…